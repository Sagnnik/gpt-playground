{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31d8de4f",
   "metadata": {},
   "source": [
    "### Attention 1: Average of previous tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a03e2aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81f0e525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.3596, -0.9152],\n",
      "        [ 0.6258,  0.0255],\n",
      "        [ 0.9545,  0.0643],\n",
      "        [ 0.3612,  1.1679],\n",
      "        [-1.3499, -0.5102],\n",
      "        [ 0.2360, -0.2398],\n",
      "        [-0.9211,  1.5433]])\n",
      "\n",
      "\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nso x[0][0][0] = 0.1808 and xbow[0][0][0] = -0.3596\\n(0.1808 - 0.3596)/2 = -0.0894 = xbow[0][1][0]\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Method 1: nested loop over batch and token\n",
    "say for batch=0 and token=5\n",
    "It will sum t=0 to t=5 then get the mean on dim 0\n",
    "This will be bag of words at batch=0\n",
    "\"\"\"\n",
    "xbow = torch.zeros((B, T, C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1] # (t, C)\n",
    "        xbow[b, t] = torch.mean(xprev, 0)\n",
    "\n",
    "print(x[0])\n",
    "print('\\n')\n",
    "print(xbow[0])\n",
    "\n",
    "\"\"\"\n",
    "so x[0][0][0] = 0.1808 and xbow[0][0][0] = -0.3596\n",
    "(0.1808 - 0.3596)/2 = -0.0894 = xbow[0][1][0]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1debc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print a=\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "print b=\n",
      "tensor([[5., 7.],\n",
      "        [2., 0.],\n",
      "        [5., 3.]])\n",
      "\n",
      "matmul with ones matrix:\n",
      "tensor([[12., 10.],\n",
      "        [12., 10.],\n",
      "        [12., 10.]])\n",
      "\n",
      "Lower triangular matrix:\n",
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "matmul with lower triangular matrix:\n",
      "tensor([[ 5.,  7.],\n",
      "        [ 7.,  7.],\n",
      "        [12., 10.]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Method 2: Matrix multiplication\n",
    "Ones matrix @ matrix = sums up every row\n",
    "or output[0][0] = input[0][0] + input[1][0] + input[2][0] + ... (upto input[T][0]) \n",
    "\n",
    "this means the first token has attended all the tokens which we dont want. Each token should only be able to see behind. So we use lower triangular matrix\n",
    "This results in every token can attend upto that token\n",
    "\n",
    "output[0][0] = input[0][0]\n",
    "output[1][0] = input[0][0] + input[1][0]\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "a = torch.ones(3, 3)\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "print(f\"print a=\\n{a}\")\n",
    "print(f\"\\nprint b=\\n{b}\")\n",
    "c = a@b\n",
    "print(f\"\\nmatmul with ones matrix:\\n{c}\")\n",
    "l = torch.tril(torch.ones(3, 3))\n",
    "print(f\"\\nLower triangular matrix:\\n{l}\")\n",
    "d = l@b\n",
    "print(f\"\\nmatmul with lower triangular matrix:\\n{d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc4c1e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean over dim=1 for lower triangular matrix:\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "\n",
      "print b=\n",
      "tensor([[5., 7.],\n",
      "        [2., 0.],\n",
      "        [5., 3.]])\n",
      "\n",
      "mean of previous tokens:\n",
      "tensor([[5.0000, 7.0000],\n",
      "        [3.5000, 3.5000],\n",
      "        [4.0000, 3.3333]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Since we are using mean of all the previous tokens as attention\n",
    "What we can do is find the mean of the lower triangual matrix before matmul\n",
    "\"\"\"\n",
    "l = torch.tril(torch.ones(3, 3))\n",
    "l = l/torch.sum(l, 1, keepdim=True)\n",
    "print(f\"mean over dim=1 for lower triangular matrix:\\n{l}\")\n",
    "print(f\"\\nprint b=\\n{b}\")\n",
    "d = l@b\n",
    "print(f\"\\nmean of previous tokens:\\n{d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f39f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets match it with out original xbow value with data x\n",
    "torch.manual_seed(1337)\n",
    "mask = torch.tril(torch.ones(T, T))\n",
    "wei = mask/mask.sum(1, keepdim=True) # (T, T) torch add the Bth dim when doing matmul\n",
    "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ---> (B, T, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2bb8ab92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tril:\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "Weights Mask:\n",
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "Probs:\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Method 3: using -inf and softmax instead of doing mean in the lower triangular matrix\n",
    "why?\n",
    "- This is the best method since we can use a weights matrix\n",
    "- instead of average we can use probablilites over the weights\n",
    "\"\"\"\n",
    "tril = torch.tril(torch.ones((T, T)))\n",
    "print(f\"Tril:\\n{tril}\")\n",
    "wei = torch.zeros((T, T)) # We are currently intializing with zeros but later it will have proper weights\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "print(f\"Weights Mask:\\n{wei}\")\n",
    "\n",
    "# Now we use softmax to convert the weights matrix into probs.\n",
    "# Since we have initialized the weights as Zeros matrix we will get the average over the rows\n",
    "wei = torch.nn.functional.softmax(wei, dim=-1)\n",
    "print(f\"Probs:\\n{wei}\")\n",
    "\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow2, xbow3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde47319",
   "metadata": {},
   "source": [
    "### Attention 2: Weighted aggregation of past tokens or Self-Attention \n",
    "We need to gather information from the past instead of just using average of previous tokens.\n",
    "\n",
    "**Self Attention**  \n",
    "Every token will emit: *Query and Key Vectors*  \n",
    "Query -> \"What am I looking for?\"  \n",
    "Key ->  \"What do I contain?\"  \n",
    "\n",
    "Now to get the afinities between the tokens now is **Query @ Key = wei**  \n",
    "We also get a *value* vector to aggregate with the *wei*\n",
    "\n",
    "**Notes:**  \n",
    "- Attention does not have a notion of space. They are simple set of vectors. Tha's why we need positional encoding\n",
    "- The batches never \"talk\" to each other. Each batch is processed in isolation\n",
    "- If you need \"encoder\" block you have to use ones matrix instead of `tril` since, all the tokens need to \"talk\" to each other. For \"deocder\" only/ autoregressive models we need the lower trainagular matrix\n",
    "- \"Self-Attention\" is when keys, queries and values comes from the same input. While \"Cross-Attention\" is when the queries comes from a different input\n",
    "- \"Scaled\" attention additionally divides `wei` by 1/sqrt(head_size) to normalize the output. without it the variance would be on the order of head_size. In my case I have 16 heads so the variance would be ~16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "19642478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights[0]:\n",
      "tensor([[-0.4407, -0.8334, -0.2557,  0.1959, -0.3142, -0.0782,  0.2719, -0.4511],\n",
      "        [-0.3253, -0.4139, -0.3152, -0.2004,  0.0047,  0.6038,  0.4913, -0.1031],\n",
      "        [ 0.1413,  0.0260,  0.0191, -0.0842, -0.1970, -0.0276, -0.0655, -0.2077],\n",
      "        [ 0.5404,  0.8446, -0.0953, -0.2124, -0.3301, -0.2483, -0.0789,  0.1475],\n",
      "        [-0.2668, -0.5456, -0.2461, -0.1401,  0.5091,  0.8362,  0.1523, -0.1997],\n",
      "        [ 0.4908,  0.2604, -0.3576, -0.2925,  0.2160, -0.6307,  0.3154, -0.1464],\n",
      "        [ 0.2691, -0.0139,  0.0187, -0.3232,  0.0930,  0.3547, -0.1371,  0.1608],\n",
      "        [-0.1132,  0.0732, -0.2387, -0.2565,  0.2314,  0.3049,  0.2012,  0.1576]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Weights[0] probs:\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5221, 0.4779, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3602, 0.3210, 0.3188, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2980, 0.4039, 0.1578, 0.1404, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1643, 0.1243, 0.1678, 0.1865, 0.3570, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2656, 0.2110, 0.1137, 0.1214, 0.2018, 0.0865, 0.0000, 0.0000],\n",
      "        [0.1761, 0.1327, 0.1371, 0.0974, 0.1476, 0.1918, 0.1173, 0.0000],\n",
      "        [0.1046, 0.1260, 0.0922, 0.0906, 0.1476, 0.1588, 0.1432, 0.1371]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn((B, T, C))\n",
    "\n",
    "# Single head of self-attention\n",
    "head_size = 16\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x) # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "v = value(x) # (B, T, 16)\n",
    "\n",
    "wei = q @ k.transpose(-2, -1) # (B, T, 16) --(transpose)--> (B, 16, T); wei = (B, T, 16) @ (B, 16, T) --(dot)--> (B, T, T)\n",
    "wei = wei * head_size**-0.5\n",
    "print(f\"Weights[0]:\\n{wei[0]}\")\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "print(f\"Weights[0] probs:\\n{wei[0]}\")\n",
    "out = wei @ v\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e639500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "karpathy (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
